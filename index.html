<!doctype html>
<html lang="en">
  <head>
	<meta name="generator" content="Hugo 0.68.3" />
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Liste - https://maverick.canhtran.me">
    <title>Maverick</title>
    <meta name="description" content="A minimal hugo theme focus on content">
    <meta property="og:title" content="" />
<meta property="og:description" content="A minimal hugo theme focus on content" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://maverick.canhtran.me/" />


    <meta itemprop="name" content="">
<meta itemprop="description" content="A minimal hugo theme focus on content">
    
    <link rel="canonical" href="https://maverick.canhtran.me/">
    <link rel="icon" href="https://maverick.canhtran.me/assets/favicon.ico">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link href="https://www.google-analytics.com" rel="preconnect" crossorigin>
    <link rel="alternate" type="application/atom+xml" title="Maverick" href="https://maverick.canhtran.me/atom.xml" />
    <link rel="alternate" type="application/json" title="Maverick" href="https://maverick.canhtran.me/feed.json" />
    <link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=">
    
    
    <style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 -apple-system,BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:0 1 auto}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:180px;width:auto;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%}table{width:100%;border-collapse:collapse}th,td{border:1px solid #ddd;text-align:left;padding:8px}th{background-color:#f2f2f2} </style>
  
    <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "WebSite",
      "name": "Maverick",
      "url": "https:\/\/maverick.canhtran.me",
      "description": "A minimal hugo theme focus on content",
      "thumbnailUrl": "https:\/\/maverick.canhtran.me\/assets\/favicon.ico",
      "license": ""
  }
  </script>
  
  
  </head>

<body>
  <a class="skip-link" href="#main">Skip to main</a>
  <main id="main">
    <div class="content">
      <header>
<p style="padding: 0;margin: 0;">
  <a href="/">
    <b>Maverick</b>
    <span class="text-stone-500 animate-blink">▮</span>
  </a>
</p>
<ul style="padding: 0;margin: 0;">
  
  
  <li class="">
    <a href="/posts/"><span>Post</span></a>
    
  <li class="">
    <a href="/about/"><span>About</span></a>
    
  </li>
</ul>
</header>
<hr class="hr-list" style="padding: 0;margin: 0;">
      <h2 id="wenwen-qiang-强文文">Wenwen Qiang (强文文)</h2>
<img class="avatar" src="./assets/qww.jpg" alt="avatar">
<p>我毕业于中国科学院大学软件研究所，现就职于中国科学院软件研究所任特别研究助理，主要从事深度学习理论、算法、策略等研究，负责时空序列（视频、气象、文档等）基础算法和及工程化落地。目前，作为技术骨干参与了国家重大专项子课题项目、国家型号项目，国自然面上项目等。以第一作者及通讯作者在国际重要学术刊物上发表学术论文30余篇(CCF-A论文12篇)，长期担任T-pami、ICML、NeurIPS，ICLR等国际顶尖期刊会议审稿人。目前主持中国科学院特别研究助理基金一项、博士后面上基金一项、及国家资助博士后研究人员计划B档基金一项。</p>
<p>I graduated from the Institute of Software at the University of Chinese Academy of Sciences and currently work as a Special Research Assistant at the Institute of Software, Chinese Academy of Sciences. My main research interests include deep learning theory, algorithms, and strategies. I am responsible for foundational algorithms and the engineering implementation of spatiotemporal sequences (such as video, meteorology, documents, etc.). Currently, I am a key technical member involved in sub-projects of major national initiatives, national model projects, and general projects funded by the National Natural Science Foundation of China. As the first author or corresponding author, I have published over 30 academic papers in leading international journals and conferences (including 12 CCF-A papers). I have also served as a long-term reviewer for top-tier journals and conferences such as T-PAMI, ICML, NeurIPS, and ICLR. At present, I am leading a Special Research Assistant Fund project from the Chinese Academy of Sciences, a general postdoctoral fund project, and a Class B fund project under the National Postdoctoral Program.</p>
<h2 id="contact">Contact</h2>
<ul>
<li><strong>GitHub:</strong> <a href="https://github.com/qwwmorning">GitHub Profile</a></li>
<li><strong>Google Scholar:</strong> <a href="https://scholar.google.com/citations?user=7U1v1vsAAAAJ&amp;hl=zh-CN">Google Scholar Profile</a></li>
</ul>
<h2 id="major-works">Major Works</h2>
<ol>
<li>
<p><strong>MetAug: Contrastive Learning via Meta Feature Augmentation</strong><br>
J Li*, W Qiang*, C Zheng, B Su, H Xiong<br>
*International Conference on Machine Learning (ICML), 2022*, pp. 12964–12978.<br>
Citations: 28</p>
</li>
<li>
<p><strong>Semi-Supervised Dimension Reduction based on Hypergraph Embedding for Hyperspectral Images</strong><br>
W Du, W Qiang, M Lv, Q Hou, L Zhen, L Jing<br>
<em>International Journal of Remote Sensing, 2018</em>, 39(6), pp. 1696–1712.<br>
Citations: 26</p>
</li>
<li>
<p><strong>Robust Local Preserving and Global Aligning Network for Adversarial Domain Adaptation</strong><br>
W Qiang, J Li, C Zheng, B Su, H Xiong<br>
<em>IEEE Transactions on Knowledge and Data Engineering, 2021</em>, 35(3), pp. 3014–3029.<br>
Citations: 25</p>
</li>
<li>
<p><strong>Interventional Contrastive Learning with Meta Semantic Regularizer</strong><br>
W Qiang, J Li, C Zheng, B Su, H Xiong<br>
<em>International Conference on Machine Learning (ICML), 2022</em>, pp. 18018–18030.<br>
Citations: 24</p>
</li>
<li>
<p><strong>Meta Attention-Generation Network for Cross-Granularity Few-Shot Learning</strong><br>
W Qiang, J Li, B Su, J Fu, H Xiong, JR Wen<br>
<em>International Journal of Computer Vision, 2023</em>, 131(5), pp. 1211–1233.<br>
Citations: 16</p>
</li>
<li>
<p><strong>Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from A Conditional Causal Perspective</strong><br>
J Li, Y Zhang, W Qiang, L Si, C Jiao, X Hu, C Zheng, F Sun<br>
<em>AAAI Conference on Artificial Intelligence (AAAI), 2023</em>.<br>
Citations: 15</p>
</li>
<li>
<p><strong>MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning</strong><br>
J Li*, W Qiang*, Y Zhang, W Mo, C Zheng, B Su, H Xiong<br>
*Neural Information Processing Systems (NeurIPS), 2022*.<br>
Citations: 13</p>
</li>
<li>
<p><strong>Robust Weighted Linear Loss Twin Multi-Class Support Vector Regression for Large-Scale Classification</strong><br>
W Qiang, J Zhang, L Zhen, L Jing<br>
<em>Signal Processing, 2020</em>, 170, 107449.<br>
Citations: 12</p>
</li>
<li>
<p><strong>Bootstrapping Informative Graph Augmentation via A Meta Learning Approach</strong><br>
H Gao, J Li, W Qiang, L Si, C Zheng, F Sun<br>
<em>International Joint Conference on Artificial Intelligence (IJCAI), 2022</em>.<br>
Citations: 11</p>
</li>
<li>
<p><strong>Auxiliary Task Guided Mean and Covariance Alignment Network for Adversarial Domain Adaptation</strong><br>
W Qiang, J Li, C Zheng, B Su<br>
<em>Knowledge-Based Systems, 2021</em>, 223, 107066.<br>
Citations: 11</p>
</li>
<li>
<p><strong>Modeling Multiple Views via Implicitly Preserving Global Consistency and Local Complementarity</strong><br>
J Li*, W Qiang*, C Zheng, B Su, F Razzak, JR Wen, H Xiong<br>
*IEEE Transactions on Knowledge and Data Engineering, 2022*.<br>
Citations: 9</p>
</li>
<li>
<p><strong>Robust Causal Graph Representation Learning against Confounding Effects</strong><br>
H Gao*, J Li*, W Qiang, L Si, B Xu, C Zheng, F Sun<br>
*AAAI Conference on Artificial Intelligence (AAAI), 2023*.<br>
Citations: 8</p>
</li>
<li>
<p><strong>RHMC: Modeling consistent information from deep multiple views via Regularized and Hybrid Multiview Coding</strong><br>
J Li*, W Qiang*, C Zheng, B Su<br>
*Knowledge-Based Systems, 2022*, 241, 108201.<br>
Citations: 8</p>
</li>
<li>
<p><strong>Zero-shot Skeleton-based Action Recognition via Mutual Information Estimation and Maximization</strong><br>
Y Zhou, W Qiang, A Rao, N Lin, B Su, J Wang<br>
<em>ACM International Conference on Multimedia (ACM MM), 2023</em>.<br>
Citations: 6</p>
</li>
<li>
<p><strong>Unified Feature Extraction Framework based on Contrastive Learning</strong><br>
H Zhang, W Qiang, J Zhang, Y Chen, L Jing<br>
<em>Knowledge-Based Systems, 2022</em>, 258, 110028.<br>
Citations: 6</p>
</li>
<li>
<p><strong>Feature Extraction Framework based on Contrastive Learning with Adaptive Positive and Negative Samples</strong><br>
H Zhang, S Zhao, W Qiang, Y Chen, L Jing<br>
<em>Neural Networks, 2022</em>, 156, pp. 244–257.<br>
Citations: 6</p>
</li>
<li>
<p><strong>TSVM-M3: Twin Support Vector Machine based on Multi-Order Moment Matching for Large-Scale Multi-Class Classification</strong><br>
W Qiang, H Zhang, J Zhang, L Jing<br>
<em>Applied Soft Computing, 2022</em>, 128, 109506.<br>
Citations: 5</p>
</li>
<li>
<p><strong>Spatio-Temporal Branching for Motion Prediction using Motion Increments</strong><br>
J Wang, Y Zhou, W Qiang, Y Ba, B Su, JR Wen<br>
<em>ACM International Conference on Multimedia (ACM MM), 2023</em>.<br>
Citations: 4</p>
</li>
<li>
<p><strong>A Novel Interval-Valued Fuzzy Multiple Twin Support Vector Machine</strong><br>
H Ju, W Qiang, L Jing<br>
<em>Iranian Journal of Fuzzy Systems, 2021</em>, 18(2), pp. 93–107.<br>
Citations: 4</p>
</li>
<li>
<p><strong>Regularized Hypothesis-Induced Wasserstein Divergence for Unsupervised Domain Adaptation</strong><br>
L Si, H Dong, W Qiang, C Zheng, J Yu, F Sun<br>
<em>Knowledge-Based Systems, 2024</em>, 283, 111162.<br>
Citations: 3</p>
</li>
<li>
<p><strong>Locality Cross-View Regression for Feature Extraction</strong><br>
J Zhang, H Zhang, W Qiang, N Deng, L Jing<br>
<em>Engineering Applications of Artificial Intelligence, 2021</em>, 105, 104414.<br>
Citations: 3</p>
</li>
<li>
<p><strong>Intriguing Property and Counterfactual Explanation of GAN for Remote Sensing Image Generation</strong><br>
X Su, W Qiang, J Hu, C Zheng, F Wu, F Sun<br>
<em>International Journal of Computer Vision, 2024</em>, 1-25.<br>
Citations: 2</p>
</li>
<li>
<p><strong>Information Theory-Guided Heuristic Progressive Multi-View Coding</strong><br>
J Li, H Gao, W Qiang, C Zheng<br>
<em>Neural Networks, 2023</em>, 167, pp. 415–432.<br>
Citations: 2</p>
</li>
<li>
<p><strong>Manifold Constraint Regularization for Remote Sensing Image Generation</strong><br>
X Su, C Zheng, W Qiang, F Wu, J Zhao, F Sun, H Xiong<br>
<em>IEEE Transactions on Geoscience and Remote Sensing, 2024</em>.<br>
Citations: 1</p>
</li>
<li>
<p><strong>Towards Task Sampler Learning for Meta-Learning</strong><br>
J Wang, W Qiang, X Su, C Zheng, F Sun, H Xiong<br>
<em>International Journal of Computer Vision, 2024</em>, 1-31.<br>
Citations: 1</p>
</li>
<li>
<p><strong>Explicitly Modeling Generality into Self-Supervised Learning</strong><br>
J Wang, W Qiang, C Zheng<br>
<em>arXiv preprint arXiv:2405.01053, 2024</em>.<br>
Citations: 1</p>
</li>
<li>
<p><strong>Not All Frequencies Are Created Equal: Towards a Dynamic Fusion of Frequencies in Time-Series Forecasting</strong><br>
X Zhang, S Zhao, Z Song, H Guo, J Zhang, C Zheng, W Qiang<br>
<em>ACM International Conference on Multimedia (ACM MM), 2024</em>.<br>
Citations: 0</p>
</li>
<li>
<p><strong>Unbiased Image Synthesis via Manifold Guidance in Diffusion Models</strong><br>
X Su, D Jia, F Wu, J Zhao, C Zheng, W Qiang<br>
<em>IEEE International Conference on Multimedia and Expo (ICME), 2024</em>.<br>
Citations: 0</p>
</li>
<li>
<p><strong>Hacking Task Confounder in Meta-Learning</strong><br>
J Wang, Y Ren, Z Song, J Zhang, C Zheng, W Qiang<br>
<em>International Joint Conference on Artificial Intelligence (IJCAI), 2024</em>.<br>
Citations: 0</p>
</li>
<li>
<p><strong>BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction</strong><br>
J Li, F Song, Y Jin, W Qiang, C Zheng, F Sun, H Xiong<br>
<em>International Conference on Learning Representations (ICLR), 2024</em>.<br>
Citations: 0</p>
</li>
<li>
<p><strong>A Novel Causal Inference Guided Feature Enhancement Framework for PolSAR Image Classification</strong><br>
H Dong, L Si, W Qiang, L Zhang, J Yu, Y Wu, C Zheng, F Sun<br>
<em>IEEE Transactions on Geoscience and Remote Sensing, 2023</em>.<br>
Citations: 0</p>
</li>
<li>
<p><strong>A Trusted Generative-Discriminative Joint Feature Learning Framework for Remote Sensing Image Classification</strong><br>
L Si, H Dong, W Qiang, Z Song, B Du, J Yu, F Sun<br>
<em>IEEE Transactions on Geoscience and Remote Sensing, 2023</em>.<br>
Citations: 0</p>
</li>
</ol>

      
    </div>
  </main>
</body>
</html>
